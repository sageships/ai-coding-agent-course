# Module 1: Foundations â€” Conceptual Guide

## ğŸ¯ The Big Picture

Before we build agents, you need to understand one thing:

**LLMs are amazing at writing code. They're terrible at editing YOUR code.**

Why? Because they can't see it.

---

## ğŸ§  The Core Problem

### What LLMs ARE Good At:

```
You: "Write a function that calculates factorial"

LLM: 
function factorial(n) {
  if (n <= 1) return 1;
  return n * factorial(n - 1);
}

âœ… Perfect! Clean code, handles edge cases.
```

### What LLMs STRUGGLE With:

```
You: "Add password reset to my Express app"

LLM: 
import { sendEmail } from './services/email';  // âŒ This file doesn't exist
import User from './models/User';              // âŒ Wrong path

app.post('/reset', async (req, res) => {
  const user = await User.findByEmail(req.body.email);  // âŒ Method doesn't exist
  ...
});

âŒ Hallucinated imports, wrong structure, made-up methods
```

---

## ğŸ’¡ Why This Happens

The LLM has no idea:
- What files exist in your project
- How your code is structured
- What functions/methods you have
- What packages you use

It's guessing. And guessing doesn't work for real code.

---

## ğŸ¯ The 3-Step Challenge

Every coding task requires:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. FIND                                                â”‚
â”‚     Which files need to change?                         â”‚
â”‚     (LLM can't do this alone â€” needs file access)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. UNDERSTAND                                          â”‚
â”‚     How does this code connect to other code?           â”‚
â”‚     (LLM needs to see related files)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. CHANGE                                              â”‚
â”‚     What exact edits need to happen?                    â”‚
â”‚     (LLM is actually great at this part!)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The LLM only struggles with steps 1 & 2. That's what this course fixes.

---

## ğŸš« Why "Just Send Everything" Doesn't Work

You might think: "Just send my whole codebase with every request!"

Let's do the math:

| Codebase Size | Tokens (~4 chars each) | Cost per Request | Problem |
|---------------|------------------------|------------------|---------|
| 10k lines | ~40k tokens | $0.50 | Expensive |
| 50k lines | ~200k tokens | $2.50 | Too big for context |
| 100k lines | ~400k tokens | Impossible | Way over limits |

Plus: **LLMs get WORSE with more context.** They lose focus.

---

## âœ¨ The Solution: Smart Context

Instead of sending everything, we:

1. **Map the codebase** â€” Create a condensed overview (~1000 tokens)
2. **Select relevant files** â€” Only what matters for this task
3. **Give LLM tools** â€” Let it request more files if needed

```
50,000 lines of code
        â†“
   Smart selection
        â†“
500 lines sent to LLM
        â†“
   Accurate response
```

This is what Cursor, Claude Code, and Aider all do.

---

## ğŸ”— The Architecture

Every AI coding tool has 4 parts:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER REQUEST                        â”‚
â”‚            "Add password reset feature"                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CONTEXT SYSTEM                         â”‚
â”‚   â€¢ Repo map (what files/functions exist)              â”‚
â”‚   â€¢ Smart file selection                               â”‚
â”‚   â€¢ Embeddings search                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   TOOL SYSTEM                          â”‚
â”‚   â€¢ read_file, write_file                              â”‚
â”‚   â€¢ run_command, search_files                          â”‚
â”‚   â€¢ LLM decides which to use                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AGENT LOOP                            â”‚
â”‚   â€¢ LLM acts â†’ observes â†’ acts â†’ observes              â”‚
â”‚   â€¢ Continues until task complete                      â”‚
â”‚   â€¢ Handles errors, retries                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RESULT                              â”‚
â”‚            Code changes applied to files               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š What Each Module Covers

| Module | What You Learn |
|--------|----------------|
| **1. Foundations** (this) | The problem + architecture overview |
| **2. Tool System** | How LLMs call functions |
| **3. Context** | How to show LLMs your codebase |
| **4. Edits** | Reliable code modification |
| **5. Agent Loop** | Putting it all together |

---

## âœ… Key Takeaways

1. LLMs are great at code generation, bad at codebase understanding
2. Sending your whole codebase doesn't work (cost + context limits)
3. Smart context selection is the secret sauce
4. Tools let LLMs take actions (read files, run commands)
5. The agent loop ties everything together

---

## ğŸ“º Video Flow

1. Start with the ChatGPT demo (good at isolated code, bad at real projects)
2. Show the 3-step challenge diagram
3. Explain why "send everything" fails (do the math)
4. Introduce the 4-part architecture
5. Preview what we'll build

---

**Next:** See `demo.ts` for basic LLM API calls
